# -*- coding: utf-8 -*-
"""MAE (4).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/131g4K3ym982fe_3AObKoDQzy7NtSeAy8

<a href="https://colab.research.google.com/github/Lucas-Monteiro-Henriques/Implement_VISIONTS/blob/main/MAE.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

Importei MAE do Facebook
"""

import numpy as np
import pandas as pd
import sys
import os
import subprocess
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import acf
from scipy.signal import find_peaks
from skimage.transform import resize
import urllib.request


import torch
import timm
from timm.models.vision_transformer import PatchEmbed, Block
np.float = float

import matplotlib.pyplot as plt
from PIL import Image

repo_dir = 'mae'
repo_url = 'https://github.com/facebookresearch/mae.git'

if 'google.colab' in sys.modules:
    print('Running in Colab.')
    !pip3 install timm==0.4.5  # 0.3.2 does not work in Colab
    if not os.path.exists('mae'):
        !git clone https://github.com/facebookresearch/mae.git
    sys.path.append('./mae')
else:
    if not os.path.exists(repo_dir):
        print(f'Cloned in : {repo_dir}')
        subprocess.run(['git', 'clone', repo_url], check=True)
    else:
        print(f'Repository already exists in {repo_dir}')

if os.path.exists('pytorch_image_models'):
    pass
else:
    !git clone https://github.com/huggingface/pytorch-image-models.git
    os.rename('pytorch-image-models', 'pytorch_image_models') #renomeia a pasta porque dá conflito nos imports

# from pytorch_image_models.timm.models.vision_transformer import PatchEmbed, Block

mae_path = os.path.abspath("mae")
if mae_path not in sys.path:
    sys.path.insert(0, mae_path)

from models_mae import mae_vit_base_patch16

model = mae_vit_base_patch16()

"""Implementação do Algoritmo de transformação das séries temporais 1D para 2D"""

df = pd.read_csv("https://github.com/zhouhaoyi/ETDataset/raw/main/ETT-small/ETTm1.csv")


serie = df["OT"].values[:66000]

acf_vals = acf(serie, nlags=min(500, len(serie)//2), fft=True)

lags = np.arange(1, len(acf_vals))
acf_sem_lag0 = acf_vals[1:]
peaks, _ = find_peaks(acf_sem_lag0, height=0.1)
P = 96

if len(peaks) == 0:
    P = 1
else:
    P = peaks[0] + 1

print(f"Periodicidade estimada: {P}")

L = (len(serie) // P) * P
serie_cortada = serie[:L]


matriz_2d = serie_cortada.reshape(P, L // P)
print("Matriz 2D:\n", matriz_2d)

"""Normalization do Iraw

"""

import numpy as np
from statistics import mean
desvio_padrao = np.std(matriz_2d)
print(desvio_padrao)
mean  = np.mean(matriz_2d)
print(mean)

r = 0.4
Inorm = r * (matriz_2d - mean)/ desvio_padrao
print(Inorm)

"""Esse é o algorimo do Alignment, mas não foi testado, pois o MAE do Facebook precisa ser alterado na parte da mascara

"""

L = 96
H = 96
c = 0.4
S = 1
N = max(Inorm.shape)

# Etapa 1: Render Igray (imagem 3 canais iguais)
Igray = np.stack([Inorm] * 3, axis=-1)

# Etapa 2: Alignment
n = int(np.floor(c * N * L / (L + H)))  # número de patches visíveis na horizontal
target_shape = (N * S, n * S)           # shape final da imagem após resize

# Resize Igray (mantendo apenas 1 canal para simplificar o MAE)
Igray_resized = resize(Inorm, target_shape, order=1, mode='reflect', anti_aliasing=False)

# Converter para imagem 3 canais (opcional, dependendo do input do MAE)
Igray_resized_3ch = np.stack([Igray_resized] * 3, axis=-1)

# Visualização
plt.imshow(Igray_resized, cmap='gray', aspect='auto')
plt.title("Igray redimensionado para Alignment (VisionTS)")
plt.colorbar()
plt.show()

# Print das formas para verificação
print("Shape original Inorm:", Inorm.shape)
print("Shape Igray:", Igray.shape)
print("Shape Igray_resized:", Igray_resized.shape)
print("Shape Igray_resized_3ch:", Igray_resized_3ch.shape)

"""Funções do MAE"""



"""Vizulização da imagem"""

# Suponha que você já tem:
# Igray_resized_3ch com shape (29, 8, 3) — imagem com 3 canais e normalizada (VisionTS-style)

# Etapa 1: Redimensionar para 224 x 224 (como esperado pelo MAE)
img = resize(Igray_resized_3ch, (224, 224), order=1, mode='reflect', anti_aliasing=False)

# Etapa 2: Visualização opcional (sem normalizar com ImageNet)
plt.rcParams['figure.figsize'] = [5, 5]
plt.imshow(img)
plt.title("Input aligned (VisionTS)")
plt.axis('off')
plt.show()

# Se for usar a função run_one_image, ela espera um tensor com valores normalizados já
# Portanto você pode usar:
img = torch.tensor(img, dtype=torch.float32)

"""Download dos pesos de Modelo

"""





# MAE com decoder
if False:
    !wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_base.pth

if True:
    url = 'https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_base.pth'
    dest = 'mae_visualize_vit_base.pth'

    if not os.path.exists(dest):
        print('Downloading MAE with decoder...')
        urllib.request.urlretrieve(url, dest)
    else:
        pass

# define the utils

imagenet_mean = np.array([0.485, 0.456, 0.406])
imagenet_std = np.array([0.229, 0.224, 0.225])

def show_image(image, title=''):
    # image is [H, W, 3]
    assert image.shape[2] == 3
    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())
    plt.title(title, fontsize=16)
    plt.axis('off')
    return

def prepare_model(chkpt_dir, arch='mae_vit_large_patch16'):
    # build model
    from models_mae import mae_vit_base_patch16
    model = mae_vit_base_patch16()

    # load model
    checkpoint = torch.load(chkpt_dir, map_location='cpu')
    msg = model.load_state_dict(checkpoint['model'], strict=False)
    print(msg)
    return model

def run_one_image_from_aligned_image(Igray_resized_3ch, model, L=96, H=96, c=0.4):
    """
    Igray_resized_3ch: imagem com 3 canais (já alinhada), shape (H, W, 3), valores já normalizados
    model: modelo MAE do repo da Meta (Vit-base etc)
    L, H, c: hiperparâmetros do VisionTS
    """
    # 1. Redimensionar para 224x224 (como esperado pelo MAE)
    img = resize(Igray_resized_3ch, (224, 224), order=1, mode='reflect', anti_aliasing=False)
    x = torch.tensor(img, dtype=torch.float32).unsqueeze(0)       # [1, H, W, C]
    if False:
        x = torch.einsum('nhwc->nchw', x).cuda()                      # [1, 3, 224, 224]
    if True:
        x = torch.einsum('nhwc->nchw', x).to(device)

    # 2. Criar máscara estruturada: lado direito mascarado
    patch_size = model.patch_embed.patch_size[0]         # geralmente 16
    num_patches_row = x.shape[2] // patch_size           # 224 / 16 = 14
    num_patches = num_patches_row ** 2                   # 14 x 14 = 196

    N = num_patches_row
    n = int(np.floor(c * N * L / (L + H)))                # número de colunas visíveis

    # 0 = visível (esquerda), 1 = mascarado (direita)
    mask = torch.zeros(N*N, device=x.device)

    for row in range(N):
        for col in range(N):
            idx = row * N + col            # ROW-MAJOR (alinha com ViT)
            mask[idx] = 1.0 if col >= N - n else 0.0   # mascara colunas da direita

    mask = mask.unsqueeze(0)  # [1, N*N]
    print(mask.view(N, N)) # [1, num_patches]
   # 90º anti-horário
    print(mask.view(N, N))
    mask = mask.reshape(1, N * N)

    # 3. Forward com máscara estruturada
    # 3. Forward com máscara estruturada
    # 3. Forward com máscara estruturada
    with torch.no_grad():
        if False:
            loss, y, _ = model(x.float(), mask=mask)         # usamos mask diretamente
        if True:
            loss, y, _ = model(x.float())
        y = model.unpatchify(y)                          # [1, 3, H, W]
        if False:
            y = torch.einsum('nchw->nhwc', y).cpu().numpy()
        if True:
            y = torch.einsum('nchw->nhwc', y).cpu()

        mask_recon = mask.unsqueeze(-1).repeat(1, 1, patch_size ** 2 * 3)
        mask_recon = model.unpatchify(mask_recon)
        mask_recon = torch.einsum('nchw->nhwc', mask_recon).cpu()

    x_vis = x.cpu()
    x_vis = torch.einsum('nchw->nhwc', x_vis)

    im_masked = x_vis * (1 - mask_recon)
    im_paste = x_vis * (1 - mask_recon) + y * mask_recon



    # 4. Visualização
    plt.rcParams['figure.figsize'] = [24, 6]
    plt.subplot(1, 4, 1); show_image(x_vis[0], "original")
    plt.subplot(1, 4, 2); show_image(im_masked[0], "structured mask")
    plt.subplot(1, 4, 3); show_image(y[0], "reconstruction")
    plt.subplot(1, 4, 4); show_image(im_paste[0], "reconstruction + visible")
    plt.show()

    return y[0], im_paste[0]  # retorno da imagem reconstruída (H, W, 3)

# Carrega o modelo base

from models_mae import mae_vit_base_patch16

chkpt_dir = 'mae_visualize_vit_base.pth'
model = mae_vit_base_patch16()
checkpoint = torch.load(chkpt_dir, map_location='cpu')
msg = model.load_state_dict(checkpoint['model'], strict=False)
print(msg)

# Enviar para GPU
model.eval()
# model.cuda()

import numpy as np
import cv2
from scipy.signal import savgol_filter

import numpy as np
import cv2

def ema_causal(img, alpha=0.9):
    # tempo no eixo x (largura)
    ema = np.zeros_like(img, dtype=np.float32)
    ema[:, 0] = img[:, 0]
    for t in range(1, img.shape[1]):
        ema[:, t] = alpha*img[:, t] + (1-alpha)*ema[:, t-1]
    return ema

def soft_threshold(x, tau):
    # shrinkage suave (wavelet-like)
    return np.sign(x) * np.maximum(np.abs(x) - tau, 0.0)

def match_stats_to_past(x, ref, L):
    """faz x ter a mesma média e std do ref, medidos no passado [0:L)"""
    mu = ref[:, :L].mean()
    sd = ref[:, :L].std() + 1e-8
    y = (x - x.mean()) / (x.std() + 1e-8) * sd + mu
    return y

def visionts_safe_detail(img_in, L, alpha=0.92, tau=0.015, beta=0.6):
    """
    img_in: np.ndarray (H,W) ou (H,W,3) em float32 [0,1] ou uint8
    L:       largura do contexto (passado) usado pelo modelo
    alpha:   suavização EMA (0.9–0.95)
    tau:     limiar do soft-threshold sobre o residual (0.01–0.03)
    beta:    ganho na reinjeção do residual limpo (0.4–0.8)
    """
    # -> grayscale float32 [0,1]
    img = img_in.astype(np.float32)
    if img.ndim == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    m, M = img.min(), img.max()
    img = (img - m) / (M - m + 1e-8)

    # 1) tendência (causal)
    trend = ema_causal(img, alpha=alpha)

    # 2) residual
    res = img - trend

    # 3) soft-threshold no residual (remove só ruído fino)
    res_denoised = soft_threshold(res, tau=tau)

    # 4) re-injeção de detalhes
    img_out = trend + beta * res_denoised

    # 5) alinhar estatísticas com o passado L do ORIGINAL (evita shift)
    img_out = match_stats_to_past(img_out, ref=img, L=L)

    # clamp opcional
    img_out = np.clip(img_out, 0.0, 1.0)
    return img_out

# Igray_resized_3ch: sua imagem temporal (H,W[,3])
# L: janela do passado usada pelo modelo (ex.: L=96)

Igray_filtered_safe = visionts_safe_detail(
    Igray_resized_3ch,
    L=L,
    alpha=0.92,   # tendência bem estável (causal)
    tau=0,    # remove só ruído fininho
    beta=1     # re-injeta 60% do detalhe limpo
)

# Se o modelo espera 3 canais:
if Igray_filtered_safe.ndim == 2:
    Igray_filtered_safe_3ch = np.repeat(Igray_filtered_safe[..., None], 3, axis=2)
else:
    Igray_filtered_safe_3ch = Igray_filtered_safe

import numpy as np
import cv2
import matplotlib.pyplot as plt

# ==========================================================
# 🔹 FILTRO TEMPORAL CAUSAL LEVE (VisionTS-safe)
# ==========================================================

def ema_filter_causal(img, alpha=0.8):
    """
    Filtro EMA causal leve (suaviza apenas ruído temporal).
    Mantém estrutura espacial e textura global.

    Parâmetros:
    - img: np.ndarray 2D ou 3D (H,W[,C])
    - alpha: 0.7–0.9 é ideal para séries temporais (0.8 padrão)
    """
    img = img.astype(np.float32)
    ema = np.zeros_like(img, dtype=np.float32)

    # assume tempo no eixo horizontal (W)
    ema[:, 0] = img[:, 0]
    for t in range(1, img.shape[1]):
        ema[:, t] = alpha * img[:, t] + (1 - alpha) * ema[:, t - 1]
    return ema


def normalize_01(img):
    """
    Normaliza entre [0,1] sem alterar contraste relativo.
    """
    img_min, img_max = img.min(), img.max()
    return (img - img_min) / (img_max - img_min + 1e-8)


def preprocess_visionts_safe(Igray_resized_3ch, alpha=0.8):
    """
    Pré-processamento leve para VisionTS:
    - Converte para cinza, se necessário.
    - Aplica EMA causal leve (temporal).
    - Normaliza em [0,1].
    """
    img = Igray_resized_3ch.astype(np.float32)

    # converte para cinza se tiver 3 canais
    if img.ndim == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # filtro EMA temporal (preserva textura)
    img_smooth = ema_filter_causal(img, alpha=alpha)

    # normalização final
    img_norm = normalize_01(img_smooth)

    return img_norm


# ==========================================================
# 🔹 EXEMPLO DE USO
# ==========================================================

# Igray_resized_3ch = cv2.imread("sua_imagem_temporal.png")

Igray_filtered_safe = preprocess_visionts_safe(Igray_resized_3ch, alpha=0.8)

# ==========================================================
# 🔹 VISUALIZAÇÃO COMPARATIVA
# ==========================================================
plt.figure(figsize=(10,5))
plt.subplot(1,2,1)
plt.imshow(Igray_resized_3ch, cmap='gray')
plt.title("Original")

plt.subplot(1,2,2)
plt.imshow(Igray_filtered_safe, cmap='gray')
plt.title("EMA leve (VisionTS-safe)")
plt.show()

# make random mask reproducible (comment out to make it change)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # usa cuda ou cpu
model = model.to(device)

# Garante reprodutibilidade na máscara aleatória
torch.manual_seed(2)

Igray_resized_3ch_tensor = torch.from_numpy(Igray_resized_3ch).float().to(device)
print('MAE with pixel reconstruction:')
reconstructed_image, imagem_correta = run_one_image_from_aligned_image(Igray_resized_3ch_tensor, model)

"""Algoritmo de reconstrução, mudar o L e H  em def reconstruct_and_evaluate_forecast para
Tabela oficial dos resultados (extraída do artigo)

"""

# 📊 Tabela oficial dos resultados no dataset ETTm1:
# -----------------------------------------------------------
# | L   | H   | MSE ↓   | MAE ↓   |
# |-----|-----|---------|---------|
# | 96  | 96  | 0.234   | 0.368   |
# | 96  | 192 | 0.286   | 0.411   |
# | 96  | 336 | 0.287   | 0.414   |
# | 96  | 720 | 0.365   | 0.470   |
# -----------------------------------------------------------
#

reconstrucao = imagem_correta.numpy() * desvio_padrao/0.4 + mean
print(reconstrucao)

print("im_paste_hw3:", type(reconstrucao), getattr(reconstrucao, "shape", None))
print("original_Inorm:", type(matriz_2d), getattr(matriz_2d, "shape", None))

def reconstruct_and_evaluate_forecast(
    y_reconstructed, original_Inorm, L=96, H=96, start_idx=None, flatten_order='C'
):
    import numpy as np
    from skimage.transform import resize
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    # 1) Reconstrução -> grayscale -> volta ao shape original
    recon_gray = y_reconstructed.mean(axis=-1)
    recon_back = resize(
        recon_gray, original_Inorm.shape, order=1, mode='reflect',
        anti_aliasing=False, preserve_range=True
    )

    P, T = original_Inorm.shape
    recon_2d  = recon_back.reshape(P, T)
    target_2d = original_Inorm.reshape(P, T)

    # 2) Define o corte (mantido)
    if start_idx is not None:
        forecast_start = int(max(0, min(start_idx, T-1)))
        pred_steps = T - forecast_start
    else:
        pred_steps = max(1, min(int(H), T))
        forecast_start = T - pred_steps

    # 3) z = target até forecast_start | recon do forecast_start ao fim (mantido)
    z = target_2d.copy()
    z[:, forecast_start:] = recon_2d[:, forecast_start:]

    # 4) MÉTRICAS APENAS NO ÚLTIMO H DA SÉRIE 1D
    target_1d = target_2d.ravel(order=flatten_order)
    recon_1d  = recon_2d.ravel(order=flatten_order)
    T_series  = target_1d.size
    H_eff     = int(min(max(1, H), T_series))
    eval_start = T_series - H_eff  # ex.: 10000-96 = 9904

    y_t_lastH = target_1d[eval_start:]
    y_p_lastH = recon_1d[eval_start:]

    mse = mean_squared_error(y_t_lastH, y_p_lastH)
    mae = mean_absolute_error(y_t_lastH, y_p_lastH)

    # recorte para plot/uso (mantido)
    recon_forecast = recon_2d[:, forecast_start:]

    print(f"[forecast] T_cols={T}, start_idx={forecast_start}, pred_steps={pred_steps}")
    print(f"[métricas último H] série_total={T_series}, H={H_eff}, eval_start={eval_start} "
          f"-> MSE={mse:.6f} | MAE={mae:.6f}")

    # agora retornamos também os vetores usados no MSE/MAE e o eval_start
    return z, recon_forecast, mse, mae, y_t_lastH, y_p_lastH, eval_start

# CNN
def reconstruct_and_evaluate_forecast(
    y_reconstructed, yreconsc , original_Inorm, L=96, H=96, start_idx=None, flatten_order='C'
):
    import numpy as np
    from skimage.transform import resize
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    # 1) Reconstrução -> grayscale -> volta ao shape original
    recon_gray = y_reconstructed.mean(axis=-1)
    recon_back = resize(
        recon_gray, original_Inorm.shape, order=1, mode='reflect',
        anti_aliasing=False, preserve_range=True
    )

    P, T = original_Inorm.shape
    recon_2d  = recon_back.reshape(P, T)
    target_2d = original_Inorm.reshape(P, T)

    # 2) Define o corte (mantido)
    if start_idx is not None:
        forecast_start = int(max(0, min(start_idx, T-1)))
        pred_steps = T - forecast_start
    else:
        pred_steps = max(1, min(int(H), T))
        forecast_start = T - pred_steps

    # 3) z = target até forecast_start | recon do forecast_start ao fim (mantido)
    z = target_2d.copy()
    z[:, forecast_start:] = recon_2d[:, forecast_start:]

    # 4) MÉTRICAS APENAS NO ÚLTIMO H DA SÉRIE 1D
    target_1d = target_2d.ravel(order=flatten_order)
    recon_1d  = recon_2d.ravel(order=flatten_order)
    T_series  = target_1d.size
    H_eff     = int(min(max(1, H), T_series))
    eval_start = T_series - H_eff  # ex.: 10000-96 = 9904

    y_t_lastH = target_1d[eval_start:]
    y_p_lastH = recon_1d[eval_start:]

    mse = mean_squared_error(y_t_lastH, yreconsc)
    mae = mean_absolute_error(y_t_lastH, yreconsc)

    # recorte para plot/uso (mantido)
    recon_forecast = recon_2d[:, forecast_start:]

    print(f"[forecast] T_cols={T}, start_idx={forecast_start}, pred_steps={pred_steps}")
    print(f"[métricas último H] série_total={T_series}, H={H_eff}, eval_start={eval_start} "
          f"-> MSE={mse:.6f} | MAE={mae:.6f}")

    # agora retornamos também os vetores usados no MSE/MAE e o eval_start
    return z, recon_forecast, mse, mae, y_t_lastH, y_p_lastH, eval_start



z, recon_fc, mse, mae, y_t_lastH, y_p_lastH, eval_start = reconstruct_and_evaluate_forecast(
    reconstrucao ,matriz_2d, H=96, flatten_order='F'
)

# plot rápido só do trecho avaliado:
import numpy as np, matplotlib.pyplot as plt
x = np.arange(len(y_t_lastH))
plt.figure(figsize=(12,3))
plt.axvline(0, ls='--', c='gray')
plt.plot(x, y_t_lastH, label='target')
plt.plot(x, y_p_lastH, label='prediction')
plt.title(f'Últimos H (MSE={mse:.4f}, MAE={mae:.4f})')
plt.legend(); plt.tight_layout(); plt.show()

import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from skimage.transform import resize
import numpy as np
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === 1. Carrega a ResNet pré-treinada no ImageNet ===
resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)

# Congela os pesos base
for param in resnet.parameters():
    param.requires_grad = False

# === 2. Substitui a camada final por regressão temporal ===
# Suponha que queremos prever H=96 pontos futuros (pode ajustar)
H = 96
resnet.fc = nn.Linear(resnet.fc.in_features, H)

model = resnet.to(device)
print("✅ ResNet carregada com pesos do ImageNet e saída =", H)

# === 3. Função de previsão ===
def predict_next_block(Igray_resized_3ch, model):
    """
    Usa a ResNet para extrair features da imagem da série temporal
    e prever o próximo bloco temporal (H pontos).
    """
    # Redimensionar para 224x224 e normalizar como ImageNet
    img = resize(Igray_resized_3ch, (224, 224), order=1, mode='reflect', anti_aliasing=False)
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    x = transform(img).unsqueeze(0).to(device).float()

    # Forward
    with torch.no_grad():
        y_pred = model(x).cpu().numpy().flatten()

    return y_pred

# === 4. Exemplo de uso ===
# Faz uma previsão para a sua imagem 3 canais já alinhada
y_pred = predict_next_block(Igray_resized_3ch, model)

print(f"Previsão gerada ({len(y_pred)} pontos):")
print(y_pred[:10])
plt.plot(y_pred)
plt.title("Saída da ResNet (previsão do próximo trecho temporal)")
plt.show()

import numpy as np
from skimage.filters import sobel
from skimage.transform import resize
from scipy.signal import savgol_filter
import matplotlib.pyplot as plt

# ==============================
# 1️⃣  TRÊS CANAIS INFORMATIVOS
# ==============================
def make_three_channels(Inorm):
    """Gera 3 canais (valor, diferença temporal e bordas)."""
    P, T = Inorm.shape
    ch0 = Inorm
    diff = np.zeros_like(Inorm)
    diff[:, 1:] = Inorm[:, 1:] - Inorm[:, :-1]
    edge = sobel(Inorm.astype(np.float32))
    I3 = np.stack([ch0, diff, edge], axis=-1)
    return I3

# ==============================
# 2️⃣  ANCORAGEM E SUAVIZAÇÃO
# ==============================
def anchor_and_blend(pred, context, P=96, smooth=True, w=0.7):
    """
    pred: vetor predito (H,)
    context: últimos valores verdadeiros da série (na escala correta)
    P: sazonalidade estimada
    smooth: suaviza saída com Savitzky–Golay
    w: peso do blend entre predição e baseline sazonal
    """
    pred = pred.astype(np.float64)
    mu_c, sd_c = float(np.mean(context)), float(np.std(context) + 1e-8)
    mu_p, sd_p = float(np.mean(pred)), float(np.std(pred) + 1e-8)

    # reescala e ancora no último ponto do contexto
    pred = mu_c + (pred - mu_p) * (sd_c / sd_p)
    pred = pred - pred[0] + context[-1]

    # baseline sazonal
    base = context[-P:]
    reps = int(np.ceil(len(pred)/P))
    base = np.tile(base, reps)[:len(pred)]

    # suavização leve
    if smooth and len(pred) >= 7:
        pred = savgol_filter(pred, window_length=7, polyorder=2, mode="interp")

    final = w * pred + (1 - w) * base
    return final


# ==============================
# 3️⃣  EXECUÇÃO ZERO-SHOT COMPLETA
# ==============================
# cria canais informativos
I3 = make_three_channels(Inorm)
Igray_resized_3ch = resize(I3, (750, 150), order=1, mode='reflect', anti_aliasing=False)

# previsões brutas da ResNet (sem treino)
y_pred = predict_next_block(Igray_resized_3ch, model)

# contexto real para ancoragem (últimos 750 valores, na escala original)
context_raw = serie[-750:]

# aplica ancoragem e blend
y_final = anchor_and_blend(y_pred, context_raw, P=96, smooth=True, w=0.75)

# ==============================
# 4️⃣  AVALIAÇÃO E PLOT
# ==============================
from sklearn.metrics import mean_absolute_error, mean_squared_error

# target verdadeiro (últimos 96 pontos)
y_true = context_raw[-96:]

mse = mean_squared_error(y_true, y_final)
mae = mean_absolute_error(y_true, y_final)
print(f"MSE={mse:.4f}, MAE={mae:.4f}")

plt.figure(figsize=(10,4))
plt.plot(y_true, label="target", color="royalblue")
plt.plot(y_final, label="prediction", color="darkorange")
plt.title(f"Zero-Shot ResNet Refinada (MSE={mse:.4f}, MAE={mae:.4f})")
plt.legend()
plt.tight_layout()
plt.show()

# ==============================================
# 🔮 Zero-Shot ResNet Forecasting (ImageNet)
# ==============================================
import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from skimage.transform import resize
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === 1. Função para carregar ResNet com pesos do ImageNet ===
def load_resnet(depth: str, out_dim: int):
    """
    depth: 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'
    out_dim: número de pontos H que queremos prever
    """
    # mapeia corretamente os pesos
    weight_enums = {
        "resnet18":  models.ResNet18_Weights.IMAGENET1K_V1,
        "resnet34":  models.ResNet34_Weights.IMAGENET1K_V1,
        "resnet50":  models.ResNet50_Weights.IMAGENET1K_V1,
        "resnet101": models.ResNet101_Weights.IMAGENET1K_V1,
        "resnet152": models.ResNet152_Weights.IMAGENET1K_V1,
    }

    w = weight_enums[depth]
    net = getattr(models, depth)(weights=w)

    # congela o backbone
    for p in net.parameters():
        p.requires_grad = False

    # substitui a camada final (fc) para previsão de H pontos
    net.fc = nn.Linear(net.fc.in_features, out_dim)
    return net.to(device).eval()

# === 2. Função de previsão ===
def predict_next_block(Igray_resized_3ch, model):
    """
    Usa a ResNet para extrair features da imagem e prever o próximo bloco temporal (H pontos)
    """
    transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.0, 0.0, 0.0],
                         std=[1.0, 1.0, 1.0])
])


    # Redimensiona para 224x224 (como ImageNet)
    img = resize(Igray_resized_3ch, (224, 224), order=1, mode='reflect', anti_aliasing=False)
    x = transform(img).unsqueeze(0).to(device).float()

    with torch.no_grad():
        y_pred = model(x).cpu().numpy().flatten()

    return y_pred

# === 3. Função para avaliar previsão ===
def evaluate_forecast(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    return mse, mae

# === 4. Rodar previsões para múltiplas ResNets ===
H = 96  # horizonte de previsão (96 passos futuros)
nets = [
    load_resnet("resnet18",  H),
    load_resnet("resnet50",  H),
    load_resnet("resnet101", H)
]

model_names = ["ResNet18", "ResNet50", "ResNet101"]
predictions = []
metrics = []

for name, net in zip(model_names, nets):
    y_pred = predict_next_block(Igray_resized_3ch, net)
    reconstrucao = (y_pred / r) * desvio_padrao + mean
    y_pred = reconstrucao
    y_true = y_t_lastH  # último trecho real da série (definido antes no notebook)
    mse, mae = evaluate_forecast(y_true, y_pred)
    metrics.append((mse, mae))
    predictions.append(y_pred)

    # Plot do resultado
    plt.figure(figsize=(10,4))
    plt.plot(y_true, label="target")
    plt.plot(y_pred, label="prediction")
    plt.title(f"{name} Zero-Shot (MSE={mse:.4f}, MAE={mae:.4f})")
    plt.legend(); plt.tight_layout()
    plt.show()

# === 5. Comparar resultados ===
for name, (mse, mae) in zip(model_names, metrics):
    print(f"{name:10s} → MSE={mse:.4f} | MAE={mae:.4f}")

# ===========================================
# 🔧 FINE-TUNING LEVE - RESNET (ETTm1) [versão final corrigida]
# ===========================================
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.models as models
from torchvision import transforms
from skimage.transform import resize
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error

# ----------------------------------------------------------
# 1️⃣ Configuração e Dataset
# ----------------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("🖥️ Dispositivo:", device)

# === Parâmetros ===
H = 96   # horizonte de previsão
L = 96   # janela de entrada
BATCH_SIZE = 8
EPOCHS = 10
LR = 1e-4

# === Carrega dataset ETTm1 ===
df = pd.read_csv("https://github.com/zhouhaoyi/ETDataset/raw/main/ETT-small/ETTm1.csv")
serie = df["OT"].values.astype(np.float32)
print("✔️ Série carregada:", serie.shape)

# ----------------------------------------------------------
# 2️⃣ Classe de Dataset: converte janelas temporais em imagens (VisionTS)
# ----------------------------------------------------------
class TimeSeriesImageDataset(Dataset):
    def __init__(self, serie, L=96, H=96, step=1):
        self.serie = serie
        self.L = L
        self.H = H
        self.step = step
        self.mean = np.mean(serie)
        self.std = np.std(serie)
        self.r = 0.4

        # ⚠️ Correto: sem normalização ImageNet
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.0, 0.0, 0.0],
                                 std=[1.0, 1.0, 1.0])
        ])

        self.samples = [i for i in range(0, len(serie) - L - H, step)]

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        i = self.samples[idx]
        x = self.serie[i:i+self.L]
        y = self.serie[i+self.L:i+self.L+self.H]

        # --- transforma janela em imagem VisionTS ---
        P = 96
        Lc = (len(x)//P)*P
        matriz_2d = x[:Lc].reshape(P, -1)

        mean, std = self.mean, self.std
        Inorm = self.r * (matriz_2d - mean) / std   # normalização VisionTS
        Igray = np.stack([Inorm]*3, axis=-1)
        Igray_resized = resize(Igray, (224,224), order=1, mode='reflect', anti_aliasing=False)

        x_tensor = self.transform(Igray_resized).float()  # [3,224,224]
        y_tensor = torch.tensor(y, dtype=torch.float32)

        return x_tensor, y_tensor

# === Cria dataloaders ===
train_ds = TimeSeriesImageDataset(serie[:60000], L=L, H=H, step=96)
test_ds  = TimeSeriesImageDataset(serie[60000:], L=L, H=H, step=96)
train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
test_dl  = DataLoader(test_ds,  batch_size=1, shuffle=False)

# ----------------------------------------------------------
# 3️⃣ Modelo - ResNet pré-treinada + ajuste final
# ----------------------------------------------------------
resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)

# descongela apenas as últimas camadas (layer4 e fc)
for name, param in resnet.named_parameters():
    if "layer4" in name or "fc" in name:
        param.requires_grad = True
    else:
        param.requires_grad = False

# substitui saída para previsão de H pontos
resnet.fc = nn.Linear(resnet.fc.in_features, H)
resnet = resnet.to(device)
print("✅ Modelo configurado para previsão de", H, "passos.")

# ----------------------------------------------------------
# 4️⃣ Treinamento leve
# ----------------------------------------------------------
criterion = nn.MSELoss()
optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=LR)

for epoch in range(EPOCHS):
    resnet.train()
    total_loss = 0
    for xb, yb in train_dl:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        pred = resnet(xb)
        loss = criterion(pred, yb)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"🌀 Epoch {epoch+1}/{EPOCHS} - Loss médio: {total_loss/len(train_dl):.6f}")

# ----------------------------------------------------------
# 5️⃣ Avaliação no conjunto de teste (corrigido)
# ----------------------------------------------------------
resnet.eval()
y_true_all, y_pred_all = [], []

with torch.no_grad():
    for xb, yb in test_dl:
        xb = xb.to(device)
        pred = resnet(xb).cpu().numpy().flatten()
        y_true_all.append(yb.numpy().flatten())
        y_pred_all.append(pred)

y_true_all = np.concatenate(y_true_all)
y_pred_all = np.concatenate(y_pred_all)

# ⚠️ Correção: modelo foi treinado com alvos reais → NÃO precisa desnormalizar novamente
y_pred_all_desnorm = y_pred_all

# Avaliação em escala real
mse_real = mean_squared_error(y_true_all, y_pred_all_desnorm)
mae_real = mean_absolute_error(y_true_all, y_pred_all_desnorm)

# Também podemos calcular métricas normalizadas apenas por referência
mean, std, r = train_ds.mean, train_ds.std, train_ds.r
y_true_norm = r * (y_true_all - mean) / std
y_pred_norm = r * (y_pred_all - mean) / std
mse_norm = mean_squared_error(y_true_norm, y_pred_norm)
mae_norm = mean_absolute_error(y_true_norm, y_pred_norm)

print(f"\n📊 Resultado final:")
print(f"→ Escala normalizada  : MSE={mse_norm:.4f} | MAE={mae_norm:.4f}")
print(f"→ Escala original     : MSE={mse_real:.4f} | MAE={mae_real:.4f}")

# ----------------------------------------------------------
# 6️⃣ Visualização de uma previsão
# ----------------------------------------------------------
plt.figure(figsize=(10,4))
plt.plot(y_true_all[:H], label="Target (Real)")
plt.plot(y_pred_all_desnorm[:H], label="Prediction (Desnormalizada)")
plt.title(f"Fine-tuning ResNet50 (H={H}) — MSE={mse_real:.4f}, MAE={mae_real:.4f}")
plt.legend()
plt.tight_layout()
plt.show()

# ===========================================
# 7️⃣ Fazer previsão com seu Igray_resized_3ch já existente
# ===========================================
from torchvision import transforms
from skimage.transform import resize

# --- 1. Se sua imagem tiver só 1 canal, converta para 3 ---
if Igray_resized.ndim == 2:  # (H, W)
    Igray_resized_3ch = np.stack([Igray_resized]*3, axis=-1)
else:
    Igray_resized_3ch = Igray_resized

# --- 2. Redimensiona e normaliza como o modelo espera (ImageNet) ---
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# --- 3. Redimensiona para 224x224 ---
img_resized = resize(Igray_resized_3ch, (224,224), order=1, mode='reflect', anti_aliasing=False)
x = transform(img_resized).unsqueeze(0).to(device).float()

# --- 4. Faz a previsão ---
resnet.eval()
with torch.no_grad():
    y_pred = resnet(x).cpu().numpy().flatten()

# --- 5. Exibe ---
print(f"📈 Previsão gerada para o seu Igray_resized_3ch ({len(y_pred)} pontos):")
print(y_pred[:10])

plt.figure(figsize=(8,3))
plt.plot(y_pred, label='Previsão ResNet (H=96)')
plt.title("Saída da ResNet fine-tunada para sua série temporal")
plt.legend()
plt.tight_layout()
plt.show()

def predict_zscore(img3ch, model):
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.0,0.0,0.0],
                             std=[1.0,1.0,1.0])
    ])
    img = resize(img3ch, (224,224), order=1, mode='reflect', anti_aliasing=False)
    x = transform(img).unsqueeze(0).to(device).float()
    with torch.no_grad():
        return model(x).cpu().numpy().flatten()

resnet50_z = load_resnet("resnet50", H)
y_pred2 = predict_zscore(Igray_resized_3ch, resnet50_z)
mse2, mae2 = evaluate(y_t_lastH, y_pred2)
print(f"Z-score → MSE={mse2:.4f} | MAE={mae2:.4f}")

plt.plot(y_t_lastH, label="Real")
plt.plot(y_pred2, label="Z-score normalization")
plt.legend(); plt.show()

nets = [
    load_resnet("resnet18",  H),
    load_resnet("resnet50",  H),
    load_resnet("resnet101", H)
]

preds = [predict(Igray_resized_3ch, m) for m in nets]
y_pred3 = np.mean(preds, axis=0)
mse3, mae3 = evaluate(y_t_lastH, y_pred3)
print(f"Ensemble → MSE={mse3:.4f} | MAE={mae3:.4f}")

plt.plot(y_t_lastH, label="Real")
plt.plot(y_pred3, label="Ensemble (18+50+101)")
plt.legend(); plt.show()

resnet_ft = load_resnet("resnet50", H)

# descongela apenas a camada fc
for n,p in resnet_ft.named_parameters():
    p.requires_grad = ("fc" in n)

optimizer = torch.optim.Adam(resnet_ft.fc.parameters(), lr=1e-4)
criterion = nn.MSELoss()

# prepara a entrada
transform_ft = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.0,0.0,0.0],
                         std=[1.0,1.0,1.0])
])
img_ft = resize(Igray_resized_3ch, (224,224), order=1, mode='reflect', anti_aliasing=False)
x_ft = transform_ft(img_ft).unsqueeze(0).to(device).float()
y_ft = torch.tensor(y_t_lastH, dtype=torch.float32).unsqueeze(0).to(device)

resnet_ft.train()
for epoch in range(3):  # fine-tuning leve
    optimizer.zero_grad()
    pred = resnet_ft(x_ft)
    loss = criterion(pred, y_ft)
    loss.backward()
    optimizer.step()
    print(f"Epoch {epoch+1}: loss={loss.item():.6f}")

# avaliação
resnet_ft.eval()
y_pred4 = resnet_ft(x_ft).cpu().detach().numpy().flatten()
mse4, mae4 = evaluate(y_t_lastH, y_pred4)
print(f"Fine-tuning leve → MSE={mse4:.4f} | MAE={mae4:.4f}")

plt.plot(y_t_lastH, label="Real")
plt.plot(y_pred4, label="Fine-tuning leve (fc)")
plt.legend(); plt.show()
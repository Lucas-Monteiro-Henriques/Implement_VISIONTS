# -*- coding: utf-8 -*-
"""MAE (4).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/131g4K3ym982fe_3AObKoDQzy7NtSeAy8

<a href="https://colab.research.google.com/github/Lucas-Monteiro-Henriques/Implement_VISIONTS/blob/main/MAE.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

Importei MAE do Facebook
"""

import numpy as np
import pandas as pd
import sys
import os
import subprocess
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import acf
from scipy.signal import find_peaks
from skimage.transform import resize
import urllib.request


import torch
import timm
from timm.models.vision_transformer import PatchEmbed, Block
np.float = float

import matplotlib.pyplot as plt
from PIL import Image

repo_dir = 'mae'
repo_url = 'https://github.com/facebookresearch/mae.git'

if 'google.colab' in sys.modules:
    print('Running in Colab.')
    !pip3 install timm==0.4.5  # 0.3.2 does not work in Colab
    if not os.path.exists('mae'):
        !git clone https://github.com/facebookresearch/mae.git
    sys.path.append('./mae')
else:
    if not os.path.exists(repo_dir):
        print(f'Cloned in : {repo_dir}')
        subprocess.run(['git', 'clone', repo_url], check=True)
    else:
        print(f'Repository already exists in {repo_dir}')

if os.path.exists('pytorch_image_models'):
    pass
else:
    !git clone https://github.com/huggingface/pytorch-image-models.git
    os.rename('pytorch-image-models', 'pytorch_image_models') #renomeia a pasta porque d√° conflito nos imports

# from pytorch_image_models.timm.models.vision_transformer import PatchEmbed, Block

mae_path = os.path.abspath("mae")
if mae_path not in sys.path:
    sys.path.insert(0, mae_path)

from models_mae import mae_vit_base_patch16

model = mae_vit_base_patch16()

"""Implementa√ß√£o do Algoritmo de transforma√ß√£o das s√©ries temporais 1D para 2D"""

df = pd.read_csv("https://github.com/zhouhaoyi/ETDataset/raw/main/ETT-small/ETTm1.csv")


serie = df["OT"].values[:66000]

acf_vals = acf(serie, nlags=min(500, len(serie)//2), fft=True)

lags = np.arange(1, len(acf_vals))
acf_sem_lag0 = acf_vals[1:]
peaks, _ = find_peaks(acf_sem_lag0, height=0.1)
P = 96

if len(peaks) == 0:
    P = 1
else:
    P = peaks[0] + 1

print(f"Periodicidade estimada: {P}")

L = (len(serie) // P) * P
serie_cortada = serie[:L]


matriz_2d = serie_cortada.reshape(P, L // P)
print("Matriz 2D:\n", matriz_2d)

"""Normalization do Iraw

"""

import numpy as np
from statistics import mean
desvio_padrao = np.std(matriz_2d)
print(desvio_padrao)
mean  = np.mean(matriz_2d)
print(mean)

r = 0.4
Inorm = r * (matriz_2d - mean)/ desvio_padrao
print(Inorm)

"""Esse √© o algorimo do Alignment, mas n√£o foi testado, pois o MAE do Facebook precisa ser alterado na parte da mascara

"""

L = 96
H = 96
c = 0.4
S = 1
N = max(Inorm.shape)

# Etapa 1: Render Igray (imagem 3 canais iguais)
Igray = np.stack([Inorm] * 3, axis=-1)

# Etapa 2: Alignment
n = int(np.floor(c * N * L / (L + H)))  # n√∫mero de patches vis√≠veis na horizontal
target_shape = (N * S, n * S)           # shape final da imagem ap√≥s resize

# Resize Igray (mantendo apenas 1 canal para simplificar o MAE)
Igray_resized = resize(Inorm, target_shape, order=1, mode='reflect', anti_aliasing=False)

# Converter para imagem 3 canais (opcional, dependendo do input do MAE)
Igray_resized_3ch = np.stack([Igray_resized] * 3, axis=-1)

# Visualiza√ß√£o
plt.imshow(Igray_resized, cmap='gray', aspect='auto')
plt.title("Igray redimensionado para Alignment (VisionTS)")
plt.colorbar()
plt.show()

# Print das formas para verifica√ß√£o
print("Shape original Inorm:", Inorm.shape)
print("Shape Igray:", Igray.shape)
print("Shape Igray_resized:", Igray_resized.shape)
print("Shape Igray_resized_3ch:", Igray_resized_3ch.shape)

"""Fun√ß√µes do MAE"""



"""Vizuliza√ß√£o da imagem"""

# Suponha que voc√™ j√° tem:
# Igray_resized_3ch com shape (29, 8, 3) ‚Äî imagem com 3 canais e normalizada (VisionTS-style)

# Etapa 1: Redimensionar para 224 x 224 (como esperado pelo MAE)
img = resize(Igray_resized_3ch, (224, 224), order=1, mode='reflect', anti_aliasing=False)

# Etapa 2: Visualiza√ß√£o opcional (sem normalizar com ImageNet)
plt.rcParams['figure.figsize'] = [5, 5]
plt.imshow(img)
plt.title("Input aligned (VisionTS)")
plt.axis('off')
plt.show()

# Se for usar a fun√ß√£o run_one_image, ela espera um tensor com valores normalizados j√°
# Portanto voc√™ pode usar:
img = torch.tensor(img, dtype=torch.float32)

"""Download dos pesos de Modelo

"""





# MAE com decoder
if False:
    !wget -nc https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_base.pth

if True:
    url = 'https://dl.fbaipublicfiles.com/mae/visualize/mae_visualize_vit_base.pth'
    dest = 'mae_visualize_vit_base.pth'

    if not os.path.exists(dest):
        print('Downloading MAE with decoder...')
        urllib.request.urlretrieve(url, dest)
    else:
        pass

# define the utils

imagenet_mean = np.array([0.485, 0.456, 0.406])
imagenet_std = np.array([0.229, 0.224, 0.225])

def show_image(image, title=''):
    # image is [H, W, 3]
    assert image.shape[2] == 3
    plt.imshow(torch.clip((image * imagenet_std + imagenet_mean) * 255, 0, 255).int())
    plt.title(title, fontsize=16)
    plt.axis('off')
    return

def prepare_model(chkpt_dir, arch='mae_vit_large_patch16'):
    # build model
    from models_mae import mae_vit_base_patch16
    model = mae_vit_base_patch16()

    # load model
    checkpoint = torch.load(chkpt_dir, map_location='cpu')
    msg = model.load_state_dict(checkpoint['model'], strict=False)
    print(msg)
    return model

def run_one_image_from_aligned_image(Igray_resized_3ch, model, L=96, H=96, c=0.4):
    """
    Igray_resized_3ch: imagem com 3 canais (j√° alinhada), shape (H, W, 3), valores j√° normalizados
    model: modelo MAE do repo da Meta (Vit-base etc)
    L, H, c: hiperpar√¢metros do VisionTS
    """
    # 1. Redimensionar para 224x224 (como esperado pelo MAE)
    img = resize(Igray_resized_3ch, (224, 224), order=1, mode='reflect', anti_aliasing=False)
    x = torch.tensor(img, dtype=torch.float32).unsqueeze(0)       # [1, H, W, C]
    if False:
        x = torch.einsum('nhwc->nchw', x).cuda()                      # [1, 3, 224, 224]
    if True:
        x = torch.einsum('nhwc->nchw', x).to(device)

    # 2. Criar m√°scara estruturada: lado direito mascarado
    patch_size = model.patch_embed.patch_size[0]         # geralmente 16
    num_patches_row = x.shape[2] // patch_size           # 224 / 16 = 14
    num_patches = num_patches_row ** 2                   # 14 x 14 = 196

    N = num_patches_row
    n = int(np.floor(c * N * L / (L + H)))                # n√∫mero de colunas vis√≠veis

    # 0 = vis√≠vel (esquerda), 1 = mascarado (direita)
    mask = torch.zeros(N*N, device=x.device)

    for row in range(N):
        for col in range(N):
            idx = row * N + col            # ROW-MAJOR (alinha com ViT)
            mask[idx] = 1.0 if col >= N - n else 0.0   # mascara colunas da direita

    mask = mask.unsqueeze(0)  # [1, N*N]
    print(mask.view(N, N)) # [1, num_patches]
   # 90¬∫ anti-hor√°rio
    print(mask.view(N, N))
    mask = mask.reshape(1, N * N)

    # 3. Forward com m√°scara estruturada
    # 3. Forward com m√°scara estruturada
    # 3. Forward com m√°scara estruturada
    with torch.no_grad():
        if False:
            loss, y, _ = model(x.float(), mask=mask)         # usamos mask diretamente
        if True:
            loss, y, _ = model(x.float())
        y = model.unpatchify(y)                          # [1, 3, H, W]
        if False:
            y = torch.einsum('nchw->nhwc', y).cpu().numpy()
        if True:
            y = torch.einsum('nchw->nhwc', y).cpu()

        mask_recon = mask.unsqueeze(-1).repeat(1, 1, patch_size ** 2 * 3)
        mask_recon = model.unpatchify(mask_recon)
        mask_recon = torch.einsum('nchw->nhwc', mask_recon).cpu()

    x_vis = x.cpu()
    x_vis = torch.einsum('nchw->nhwc', x_vis)

    im_masked = x_vis * (1 - mask_recon)
    im_paste = x_vis * (1 - mask_recon) + y * mask_recon



    # 4. Visualiza√ß√£o
    plt.rcParams['figure.figsize'] = [24, 6]
    plt.subplot(1, 4, 1); show_image(x_vis[0], "original")
    plt.subplot(1, 4, 2); show_image(im_masked[0], "structured mask")
    plt.subplot(1, 4, 3); show_image(y[0], "reconstruction")
    plt.subplot(1, 4, 4); show_image(im_paste[0], "reconstruction + visible")
    plt.show()

    return y[0], im_paste[0]  # retorno da imagem reconstru√≠da (H, W, 3)

# Carrega o modelo base

from models_mae import mae_vit_base_patch16

chkpt_dir = 'mae_visualize_vit_base.pth'
model = mae_vit_base_patch16()
checkpoint = torch.load(chkpt_dir, map_location='cpu')
msg = model.load_state_dict(checkpoint['model'], strict=False)
print(msg)

# Enviar para GPU
model.eval()
# model.cuda()

import numpy as np
import cv2
from scipy.signal import savgol_filter

import numpy as np
import cv2

def ema_causal(img, alpha=0.9):
    # tempo no eixo x (largura)
    ema = np.zeros_like(img, dtype=np.float32)
    ema[:, 0] = img[:, 0]
    for t in range(1, img.shape[1]):
        ema[:, t] = alpha*img[:, t] + (1-alpha)*ema[:, t-1]
    return ema

def soft_threshold(x, tau):
    # shrinkage suave (wavelet-like)
    return np.sign(x) * np.maximum(np.abs(x) - tau, 0.0)

def match_stats_to_past(x, ref, L):
    """faz x ter a mesma m√©dia e std do ref, medidos no passado [0:L)"""
    mu = ref[:, :L].mean()
    sd = ref[:, :L].std() + 1e-8
    y = (x - x.mean()) / (x.std() + 1e-8) * sd + mu
    return y

def visionts_safe_detail(img_in, L, alpha=0.92, tau=0.015, beta=0.6):
    """
    img_in: np.ndarray (H,W) ou (H,W,3) em float32 [0,1] ou uint8
    L:       largura do contexto (passado) usado pelo modelo
    alpha:   suaviza√ß√£o EMA (0.9‚Äì0.95)
    tau:     limiar do soft-threshold sobre o residual (0.01‚Äì0.03)
    beta:    ganho na reinje√ß√£o do residual limpo (0.4‚Äì0.8)
    """
    # -> grayscale float32 [0,1]
    img = img_in.astype(np.float32)
    if img.ndim == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    m, M = img.min(), img.max()
    img = (img - m) / (M - m + 1e-8)

    # 1) tend√™ncia (causal)
    trend = ema_causal(img, alpha=alpha)

    # 2) residual
    res = img - trend

    # 3) soft-threshold no residual (remove s√≥ ru√≠do fino)
    res_denoised = soft_threshold(res, tau=tau)

    # 4) re-inje√ß√£o de detalhes
    img_out = trend + beta * res_denoised

    # 5) alinhar estat√≠sticas com o passado L do ORIGINAL (evita shift)
    img_out = match_stats_to_past(img_out, ref=img, L=L)

    # clamp opcional
    img_out = np.clip(img_out, 0.0, 1.0)
    return img_out

# Igray_resized_3ch: sua imagem temporal (H,W[,3])
# L: janela do passado usada pelo modelo (ex.: L=96)

Igray_filtered_safe = visionts_safe_detail(
    Igray_resized_3ch,
    L=L,
    alpha=0.92,   # tend√™ncia bem est√°vel (causal)
    tau=0,    # remove s√≥ ru√≠do fininho
    beta=1     # re-injeta 60% do detalhe limpo
)

# Se o modelo espera 3 canais:
if Igray_filtered_safe.ndim == 2:
    Igray_filtered_safe_3ch = np.repeat(Igray_filtered_safe[..., None], 3, axis=2)
else:
    Igray_filtered_safe_3ch = Igray_filtered_safe

import numpy as np
import cv2
import matplotlib.pyplot as plt

# ==========================================================
# üîπ FILTRO TEMPORAL CAUSAL LEVE (VisionTS-safe)
# ==========================================================

def ema_filter_causal(img, alpha=0.8):
    """
    Filtro EMA causal leve (suaviza apenas ru√≠do temporal).
    Mant√©m estrutura espacial e textura global.

    Par√¢metros:
    - img: np.ndarray 2D ou 3D (H,W[,C])
    - alpha: 0.7‚Äì0.9 √© ideal para s√©ries temporais (0.8 padr√£o)
    """
    img = img.astype(np.float32)
    ema = np.zeros_like(img, dtype=np.float32)

    # assume tempo no eixo horizontal (W)
    ema[:, 0] = img[:, 0]
    for t in range(1, img.shape[1]):
        ema[:, t] = alpha * img[:, t] + (1 - alpha) * ema[:, t - 1]
    return ema


def normalize_01(img):
    """
    Normaliza entre [0,1] sem alterar contraste relativo.
    """
    img_min, img_max = img.min(), img.max()
    return (img - img_min) / (img_max - img_min + 1e-8)


def preprocess_visionts_safe(Igray_resized_3ch, alpha=0.8):
    """
    Pr√©-processamento leve para VisionTS:
    - Converte para cinza, se necess√°rio.
    - Aplica EMA causal leve (temporal).
    - Normaliza em [0,1].
    """
    img = Igray_resized_3ch.astype(np.float32)

    # converte para cinza se tiver 3 canais
    if img.ndim == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # filtro EMA temporal (preserva textura)
    img_smooth = ema_filter_causal(img, alpha=alpha)

    # normaliza√ß√£o final
    img_norm = normalize_01(img_smooth)

    return img_norm


# ==========================================================
# üîπ EXEMPLO DE USO
# ==========================================================

# Igray_resized_3ch = cv2.imread("sua_imagem_temporal.png")

Igray_filtered_safe = preprocess_visionts_safe(Igray_resized_3ch, alpha=0.8)

# ==========================================================
# üîπ VISUALIZA√á√ÉO COMPARATIVA
# ==========================================================
plt.figure(figsize=(10,5))
plt.subplot(1,2,1)
plt.imshow(Igray_resized_3ch, cmap='gray')
plt.title("Original")

plt.subplot(1,2,2)
plt.imshow(Igray_filtered_safe, cmap='gray')
plt.title("EMA leve (VisionTS-safe)")
plt.show()

# make random mask reproducible (comment out to make it change)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # usa cuda ou cpu
model = model.to(device)

# Garante reprodutibilidade na m√°scara aleat√≥ria
torch.manual_seed(2)

Igray_resized_3ch_tensor = torch.from_numpy(Igray_resized_3ch).float().to(device)
print('MAE with pixel reconstruction:')
reconstructed_image, imagem_correta = run_one_image_from_aligned_image(Igray_resized_3ch_tensor, model)

"""Algoritmo de reconstru√ß√£o, mudar o L e H  em def reconstruct_and_evaluate_forecast para
Tabela oficial dos resultados (extra√≠da do artigo)

"""

# üìä Tabela oficial dos resultados no dataset ETTm1:
# -----------------------------------------------------------
# | L   | H   | MSE ‚Üì   | MAE ‚Üì   |
# |-----|-----|---------|---------|
# | 96  | 96  | 0.234   | 0.368   |
# | 96  | 192 | 0.286   | 0.411   |
# | 96  | 336 | 0.287   | 0.414   |
# | 96  | 720 | 0.365   | 0.470   |
# -----------------------------------------------------------
#

reconstrucao = imagem_correta.numpy() * desvio_padrao/0.4 + mean
print(reconstrucao)

print("im_paste_hw3:", type(reconstrucao), getattr(reconstrucao, "shape", None))
print("original_Inorm:", type(matriz_2d), getattr(matriz_2d, "shape", None))

def reconstruct_and_evaluate_forecast(
    y_reconstructed, original_Inorm, L=96, H=96, start_idx=None, flatten_order='C'
):
    import numpy as np
    from skimage.transform import resize
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    # 1) Reconstru√ß√£o -> grayscale -> volta ao shape original
    recon_gray = y_reconstructed.mean(axis=-1)
    recon_back = resize(
        recon_gray, original_Inorm.shape, order=1, mode='reflect',
        anti_aliasing=False, preserve_range=True
    )

    P, T = original_Inorm.shape
    recon_2d  = recon_back.reshape(P, T)
    target_2d = original_Inorm.reshape(P, T)

    # 2) Define o corte (mantido)
    if start_idx is not None:
        forecast_start = int(max(0, min(start_idx, T-1)))
        pred_steps = T - forecast_start
    else:
        pred_steps = max(1, min(int(H), T))
        forecast_start = T - pred_steps

    # 3) z = target at√© forecast_start | recon do forecast_start ao fim (mantido)
    z = target_2d.copy()
    z[:, forecast_start:] = recon_2d[:, forecast_start:]

    # 4) M√âTRICAS APENAS NO √öLTIMO H DA S√âRIE 1D
    target_1d = target_2d.ravel(order=flatten_order)
    recon_1d  = recon_2d.ravel(order=flatten_order)
    T_series  = target_1d.size
    H_eff     = int(min(max(1, H), T_series))
    eval_start = T_series - H_eff  # ex.: 10000-96 = 9904

    y_t_lastH = target_1d[eval_start:]
    y_p_lastH = recon_1d[eval_start:]

    mse = mean_squared_error(y_t_lastH, y_p_lastH)
    mae = mean_absolute_error(y_t_lastH, y_p_lastH)

    # recorte para plot/uso (mantido)
    recon_forecast = recon_2d[:, forecast_start:]

    print(f"[forecast] T_cols={T}, start_idx={forecast_start}, pred_steps={pred_steps}")
    print(f"[m√©tricas √∫ltimo H] s√©rie_total={T_series}, H={H_eff}, eval_start={eval_start} "
          f"-> MSE={mse:.6f} | MAE={mae:.6f}")

    # agora retornamos tamb√©m os vetores usados no MSE/MAE e o eval_start
    return z, recon_forecast, mse, mae, y_t_lastH, y_p_lastH, eval_start

# CNN
def reconstruct_and_evaluate_forecast(
    y_reconstructed, yreconsc , original_Inorm, L=96, H=96, start_idx=None, flatten_order='C'
):
    import numpy as np
    from skimage.transform import resize
    from sklearn.metrics import mean_squared_error, mean_absolute_error

    # 1) Reconstru√ß√£o -> grayscale -> volta ao shape original
    recon_gray = y_reconstructed.mean(axis=-1)
    recon_back = resize(
        recon_gray, original_Inorm.shape, order=1, mode='reflect',
        anti_aliasing=False, preserve_range=True
    )

    P, T = original_Inorm.shape
    recon_2d  = recon_back.reshape(P, T)
    target_2d = original_Inorm.reshape(P, T)

    # 2) Define o corte (mantido)
    if start_idx is not None:
        forecast_start = int(max(0, min(start_idx, T-1)))
        pred_steps = T - forecast_start
    else:
        pred_steps = max(1, min(int(H), T))
        forecast_start = T - pred_steps

    # 3) z = target at√© forecast_start | recon do forecast_start ao fim (mantido)
    z = target_2d.copy()
    z[:, forecast_start:] = recon_2d[:, forecast_start:]

    # 4) M√âTRICAS APENAS NO √öLTIMO H DA S√âRIE 1D
    target_1d = target_2d.ravel(order=flatten_order)
    recon_1d  = recon_2d.ravel(order=flatten_order)
    T_series  = target_1d.size
    H_eff     = int(min(max(1, H), T_series))
    eval_start = T_series - H_eff  # ex.: 10000-96 = 9904

    y_t_lastH = target_1d[eval_start:]
    y_p_lastH = recon_1d[eval_start:]

    mse = mean_squared_error(y_t_lastH, yreconsc)
    mae = mean_absolute_error(y_t_lastH, yreconsc)

    # recorte para plot/uso (mantido)
    recon_forecast = recon_2d[:, forecast_start:]

    print(f"[forecast] T_cols={T}, start_idx={forecast_start}, pred_steps={pred_steps}")
    print(f"[m√©tricas √∫ltimo H] s√©rie_total={T_series}, H={H_eff}, eval_start={eval_start} "
          f"-> MSE={mse:.6f} | MAE={mae:.6f}")

    # agora retornamos tamb√©m os vetores usados no MSE/MAE e o eval_start
    return z, recon_forecast, mse, mae, y_t_lastH, y_p_lastH, eval_start



z, recon_fc, mse, mae, y_t_lastH, y_p_lastH, eval_start = reconstruct_and_evaluate_forecast(
    reconstrucao ,matriz_2d, H=96, flatten_order='F'
)

# plot r√°pido s√≥ do trecho avaliado:
import numpy as np, matplotlib.pyplot as plt
x = np.arange(len(y_t_lastH))
plt.figure(figsize=(12,3))
plt.axvline(0, ls='--', c='gray')
plt.plot(x, y_t_lastH, label='target')
plt.plot(x, y_p_lastH, label='prediction')
plt.title(f'√öltimos H (MSE={mse:.4f}, MAE={mae:.4f})')
plt.legend(); plt.tight_layout(); plt.show()

import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from skimage.transform import resize
import numpy as np
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === 1. Carrega a ResNet pr√©-treinada no ImageNet ===
resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)

# Congela os pesos base
for param in resnet.parameters():
    param.requires_grad = False

# === 2. Substitui a camada final por regress√£o temporal ===
# Suponha que queremos prever H=96 pontos futuros (pode ajustar)
H = 96
resnet.fc = nn.Linear(resnet.fc.in_features, H)

model = resnet.to(device)
print("‚úÖ ResNet carregada com pesos do ImageNet e sa√≠da =", H)

# === 3. Fun√ß√£o de previs√£o ===
def predict_next_block(Igray_resized_3ch, model):
    """
    Usa a ResNet para extrair features da imagem da s√©rie temporal
    e prever o pr√≥ximo bloco temporal (H pontos).
    """
    # Redimensionar para 224x224 e normalizar como ImageNet
    img = resize(Igray_resized_3ch, (224, 224), order=1, mode='reflect', anti_aliasing=False)
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    x = transform(img).unsqueeze(0).to(device).float()

    # Forward
    with torch.no_grad():
        y_pred = model(x).cpu().numpy().flatten()

    return y_pred

# === 4. Exemplo de uso ===
# Faz uma previs√£o para a sua imagem 3 canais j√° alinhada
y_pred = predict_next_block(Igray_resized_3ch, model)

print(f"Previs√£o gerada ({len(y_pred)} pontos):")
print(y_pred[:10])
plt.plot(y_pred)
plt.title("Sa√≠da da ResNet (previs√£o do pr√≥ximo trecho temporal)")
plt.show()

import numpy as np
from skimage.filters import sobel
from skimage.transform import resize
from scipy.signal import savgol_filter
import matplotlib.pyplot as plt

# ==============================
# 1Ô∏è‚É£  TR√äS CANAIS INFORMATIVOS
# ==============================
def make_three_channels(Inorm):
    """Gera 3 canais (valor, diferen√ßa temporal e bordas)."""
    P, T = Inorm.shape
    ch0 = Inorm
    diff = np.zeros_like(Inorm)
    diff[:, 1:] = Inorm[:, 1:] - Inorm[:, :-1]
    edge = sobel(Inorm.astype(np.float32))
    I3 = np.stack([ch0, diff, edge], axis=-1)
    return I3

# ==============================
# 2Ô∏è‚É£  ANCORAGEM E SUAVIZA√á√ÉO
# ==============================
def anchor_and_blend(pred, context, P=96, smooth=True, w=0.7):
    """
    pred: vetor predito (H,)
    context: √∫ltimos valores verdadeiros da s√©rie (na escala correta)
    P: sazonalidade estimada
    smooth: suaviza sa√≠da com Savitzky‚ÄìGolay
    w: peso do blend entre predi√ß√£o e baseline sazonal
    """
    pred = pred.astype(np.float64)
    mu_c, sd_c = float(np.mean(context)), float(np.std(context) + 1e-8)
    mu_p, sd_p = float(np.mean(pred)), float(np.std(pred) + 1e-8)

    # reescala e ancora no √∫ltimo ponto do contexto
    pred = mu_c + (pred - mu_p) * (sd_c / sd_p)
    pred = pred - pred[0] + context[-1]

    # baseline sazonal
    base = context[-P:]
    reps = int(np.ceil(len(pred)/P))
    base = np.tile(base, reps)[:len(pred)]

    # suaviza√ß√£o leve
    if smooth and len(pred) >= 7:
        pred = savgol_filter(pred, window_length=7, polyorder=2, mode="interp")

    final = w * pred + (1 - w) * base
    return final


# ==============================
# 3Ô∏è‚É£  EXECU√á√ÉO ZERO-SHOT COMPLETA
# ==============================
# cria canais informativos
I3 = make_three_channels(Inorm)
Igray_resized_3ch = resize(I3, (750, 150), order=1, mode='reflect', anti_aliasing=False)

# previs√µes brutas da ResNet (sem treino)
y_pred = predict_next_block(Igray_resized_3ch, model)

# contexto real para ancoragem (√∫ltimos 750 valores, na escala original)
context_raw = serie[-750:]

# aplica ancoragem e blend
y_final = anchor_and_blend(y_pred, context_raw, P=96, smooth=True, w=0.75)

# ==============================
# 4Ô∏è‚É£  AVALIA√á√ÉO E PLOT
# ==============================
from sklearn.metrics import mean_absolute_error, mean_squared_error

# target verdadeiro (√∫ltimos 96 pontos)
y_true = context_raw[-96:]

mse = mean_squared_error(y_true, y_final)
mae = mean_absolute_error(y_true, y_final)
print(f"MSE={mse:.4f}, MAE={mae:.4f}")

plt.figure(figsize=(10,4))
plt.plot(y_true, label="target", color="royalblue")
plt.plot(y_final, label="prediction", color="darkorange")
plt.title(f"Zero-Shot ResNet Refinada (MSE={mse:.4f}, MAE={mae:.4f})")
plt.legend()
plt.tight_layout()
plt.show()

# ==============================================
# üîÆ Zero-Shot ResNet Forecasting (ImageNet)
# ==============================================
import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from skimage.transform import resize
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === 1. Fun√ß√£o para carregar ResNet com pesos do ImageNet ===
def load_resnet(depth: str, out_dim: int):
    """
    depth: 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'
    out_dim: n√∫mero de pontos H que queremos prever
    """
    # mapeia corretamente os pesos
    weight_enums = {
        "resnet18":  models.ResNet18_Weights.IMAGENET1K_V1,
        "resnet34":  models.ResNet34_Weights.IMAGENET1K_V1,
        "resnet50":  models.ResNet50_Weights.IMAGENET1K_V1,
        "resnet101": models.ResNet101_Weights.IMAGENET1K_V1,
        "resnet152": models.ResNet152_Weights.IMAGENET1K_V1,
    }

    w = weight_enums[depth]
    net = getattr(models, depth)(weights=w)

    # congela o backbone
    for p in net.parameters():
        p.requires_grad = False

    # substitui a camada final (fc) para previs√£o de H pontos
    net.fc = nn.Linear(net.fc.in_features, out_dim)
    return net.to(device).eval()

# === 2. Fun√ß√£o de previs√£o ===
def predict_next_block(Igray_resized_3ch, model):
    """
    Usa a ResNet para extrair features da imagem e prever o pr√≥ximo bloco temporal (H pontos)
    """
    transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.0, 0.0, 0.0],
                         std=[1.0, 1.0, 1.0])
])


    # Redimensiona para 224x224 (como ImageNet)
    img = resize(Igray_resized_3ch, (224, 224), order=1, mode='reflect', anti_aliasing=False)
    x = transform(img).unsqueeze(0).to(device).float()

    with torch.no_grad():
        y_pred = model(x).cpu().numpy().flatten()

    return y_pred

# === 3. Fun√ß√£o para avaliar previs√£o ===
def evaluate_forecast(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    return mse, mae

# === 4. Rodar previs√µes para m√∫ltiplas ResNets ===
H = 96  # horizonte de previs√£o (96 passos futuros)
nets = [
    load_resnet("resnet18",  H),
    load_resnet("resnet50",  H),
    load_resnet("resnet101", H)
]

model_names = ["ResNet18", "ResNet50", "ResNet101"]
predictions = []
metrics = []

for name, net in zip(model_names, nets):
    y_pred = predict_next_block(Igray_resized_3ch, net)
    reconstrucao = (y_pred / r) * desvio_padrao + mean
    y_pred = reconstrucao
    y_true = y_t_lastH  # √∫ltimo trecho real da s√©rie (definido antes no notebook)
    mse, mae = evaluate_forecast(y_true, y_pred)
    metrics.append((mse, mae))
    predictions.append(y_pred)

    # Plot do resultado
    plt.figure(figsize=(10,4))
    plt.plot(y_true, label="target")
    plt.plot(y_pred, label="prediction")
    plt.title(f"{name} Zero-Shot (MSE={mse:.4f}, MAE={mae:.4f})")
    plt.legend(); plt.tight_layout()
    plt.show()

# === 5. Comparar resultados ===
for name, (mse, mae) in zip(model_names, metrics):
    print(f"{name:10s} ‚Üí MSE={mse:.4f} | MAE={mae:.4f}")

# ===========================================
# üîß FINE-TUNING LEVE - RESNET (ETTm1) [vers√£o final corrigida]
# ===========================================
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.models as models
from torchvision import transforms
from skimage.transform import resize
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error

# ----------------------------------------------------------
# 1Ô∏è‚É£ Configura√ß√£o e Dataset
# ----------------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("üñ•Ô∏è Dispositivo:", device)

# === Par√¢metros ===
H = 96   # horizonte de previs√£o
L = 96   # janela de entrada
BATCH_SIZE = 8
EPOCHS = 10
LR = 1e-4

# === Carrega dataset ETTm1 ===
df = pd.read_csv("https://github.com/zhouhaoyi/ETDataset/raw/main/ETT-small/ETTm1.csv")
serie = df["OT"].values.astype(np.float32)
print("‚úîÔ∏è S√©rie carregada:", serie.shape)

# ----------------------------------------------------------
# 2Ô∏è‚É£ Classe de Dataset: converte janelas temporais em imagens (VisionTS)
# ----------------------------------------------------------
class TimeSeriesImageDataset(Dataset):
    def __init__(self, serie, L=96, H=96, step=1):
        self.serie = serie
        self.L = L
        self.H = H
        self.step = step
        self.mean = np.mean(serie)
        self.std = np.std(serie)
        self.r = 0.4

        # ‚ö†Ô∏è Correto: sem normaliza√ß√£o ImageNet
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.0, 0.0, 0.0],
                                 std=[1.0, 1.0, 1.0])
        ])

        self.samples = [i for i in range(0, len(serie) - L - H, step)]

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        i = self.samples[idx]
        x = self.serie[i:i+self.L]
        y = self.serie[i+self.L:i+self.L+self.H]

        # --- transforma janela em imagem VisionTS ---
        P = 96
        Lc = (len(x)//P)*P
        matriz_2d = x[:Lc].reshape(P, -1)

        mean, std = self.mean, self.std
        Inorm = self.r * (matriz_2d - mean) / std   # normaliza√ß√£o VisionTS
        Igray = np.stack([Inorm]*3, axis=-1)
        Igray_resized = resize(Igray, (224,224), order=1, mode='reflect', anti_aliasing=False)

        x_tensor = self.transform(Igray_resized).float()  # [3,224,224]
        y_tensor = torch.tensor(y, dtype=torch.float32)

        return x_tensor, y_tensor

# === Cria dataloaders ===
train_ds = TimeSeriesImageDataset(serie[:60000], L=L, H=H, step=96)
test_ds  = TimeSeriesImageDataset(serie[60000:], L=L, H=H, step=96)
train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
test_dl  = DataLoader(test_ds,  batch_size=1, shuffle=False)

# ----------------------------------------------------------
# 3Ô∏è‚É£ Modelo - ResNet pr√©-treinada + ajuste final
# ----------------------------------------------------------
resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)

# descongela apenas as √∫ltimas camadas (layer4 e fc)
for name, param in resnet.named_parameters():
    if "layer4" in name or "fc" in name:
        param.requires_grad = True
    else:
        param.requires_grad = False

# substitui sa√≠da para previs√£o de H pontos
resnet.fc = nn.Linear(resnet.fc.in_features, H)
resnet = resnet.to(device)
print("‚úÖ Modelo configurado para previs√£o de", H, "passos.")

# ----------------------------------------------------------
# 4Ô∏è‚É£ Treinamento leve
# ----------------------------------------------------------
criterion = nn.MSELoss()
optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=LR)

for epoch in range(EPOCHS):
    resnet.train()
    total_loss = 0
    for xb, yb in train_dl:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        pred = resnet(xb)
        loss = criterion(pred, yb)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"üåÄ Epoch {epoch+1}/{EPOCHS} - Loss m√©dio: {total_loss/len(train_dl):.6f}")

# ----------------------------------------------------------
# 5Ô∏è‚É£ Avalia√ß√£o no conjunto de teste (corrigido)
# ----------------------------------------------------------
resnet.eval()
y_true_all, y_pred_all = [], []

with torch.no_grad():
    for xb, yb in test_dl:
        xb = xb.to(device)
        pred = resnet(xb).cpu().numpy().flatten()
        y_true_all.append(yb.numpy().flatten())
        y_pred_all.append(pred)

y_true_all = np.concatenate(y_true_all)
y_pred_all = np.concatenate(y_pred_all)

# ‚ö†Ô∏è Corre√ß√£o: modelo foi treinado com alvos reais ‚Üí N√ÉO precisa desnormalizar novamente
y_pred_all_desnorm = y_pred_all

# Avalia√ß√£o em escala real
mse_real = mean_squared_error(y_true_all, y_pred_all_desnorm)
mae_real = mean_absolute_error(y_true_all, y_pred_all_desnorm)

# Tamb√©m podemos calcular m√©tricas normalizadas apenas por refer√™ncia
mean, std, r = train_ds.mean, train_ds.std, train_ds.r
y_true_norm = r * (y_true_all - mean) / std
y_pred_norm = r * (y_pred_all - mean) / std
mse_norm = mean_squared_error(y_true_norm, y_pred_norm)
mae_norm = mean_absolute_error(y_true_norm, y_pred_norm)

print(f"\nüìä Resultado final:")
print(f"‚Üí Escala normalizada  : MSE={mse_norm:.4f} | MAE={mae_norm:.4f}")
print(f"‚Üí Escala original     : MSE={mse_real:.4f} | MAE={mae_real:.4f}")

# ----------------------------------------------------------
# 6Ô∏è‚É£ Visualiza√ß√£o de uma previs√£o
# ----------------------------------------------------------
plt.figure(figsize=(10,4))
plt.plot(y_true_all[:H], label="Target (Real)")
plt.plot(y_pred_all_desnorm[:H], label="Prediction (Desnormalizada)")
plt.title(f"Fine-tuning ResNet50 (H={H}) ‚Äî MSE={mse_real:.4f}, MAE={mae_real:.4f}")
plt.legend()
plt.tight_layout()
plt.show()

# ===========================================
# 7Ô∏è‚É£ Fazer previs√£o com seu Igray_resized_3ch j√° existente
# ===========================================
from torchvision import transforms
from skimage.transform import resize

# --- 1. Se sua imagem tiver s√≥ 1 canal, converta para 3 ---
if Igray_resized.ndim == 2:  # (H, W)
    Igray_resized_3ch = np.stack([Igray_resized]*3, axis=-1)
else:
    Igray_resized_3ch = Igray_resized

# --- 2. Redimensiona e normaliza como o modelo espera (ImageNet) ---
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# --- 3. Redimensiona para 224x224 ---
img_resized = resize(Igray_resized_3ch, (224,224), order=1, mode='reflect', anti_aliasing=False)
x = transform(img_resized).unsqueeze(0).to(device).float()

# --- 4. Faz a previs√£o ---
resnet.eval()
with torch.no_grad():
    y_pred = resnet(x).cpu().numpy().flatten()

# --- 5. Exibe ---
print(f"üìà Previs√£o gerada para o seu Igray_resized_3ch ({len(y_pred)} pontos):")
print(y_pred[:10])

plt.figure(figsize=(8,3))
plt.plot(y_pred, label='Previs√£o ResNet (H=96)')
plt.title("Sa√≠da da ResNet fine-tunada para sua s√©rie temporal")
plt.legend()
plt.tight_layout()
plt.show()

def predict_zscore(img3ch, model):
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.0,0.0,0.0],
                             std=[1.0,1.0,1.0])
    ])
    img = resize(img3ch, (224,224), order=1, mode='reflect', anti_aliasing=False)
    x = transform(img).unsqueeze(0).to(device).float()
    with torch.no_grad():
        return model(x).cpu().numpy().flatten()

resnet50_z = load_resnet("resnet50", H)
y_pred2 = predict_zscore(Igray_resized_3ch, resnet50_z)
mse2, mae2 = evaluate(y_t_lastH, y_pred2)
print(f"Z-score ‚Üí MSE={mse2:.4f} | MAE={mae2:.4f}")

plt.plot(y_t_lastH, label="Real")
plt.plot(y_pred2, label="Z-score normalization")
plt.legend(); plt.show()

nets = [
    load_resnet("resnet18",  H),
    load_resnet("resnet50",  H),
    load_resnet("resnet101", H)
]

preds = [predict(Igray_resized_3ch, m) for m in nets]
y_pred3 = np.mean(preds, axis=0)
mse3, mae3 = evaluate(y_t_lastH, y_pred3)
print(f"Ensemble ‚Üí MSE={mse3:.4f} | MAE={mae3:.4f}")

plt.plot(y_t_lastH, label="Real")
plt.plot(y_pred3, label="Ensemble (18+50+101)")
plt.legend(); plt.show()

resnet_ft = load_resnet("resnet50", H)

# descongela apenas a camada fc
for n,p in resnet_ft.named_parameters():
    p.requires_grad = ("fc" in n)

optimizer = torch.optim.Adam(resnet_ft.fc.parameters(), lr=1e-4)
criterion = nn.MSELoss()

# prepara a entrada
transform_ft = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.0,0.0,0.0],
                         std=[1.0,1.0,1.0])
])
img_ft = resize(Igray_resized_3ch, (224,224), order=1, mode='reflect', anti_aliasing=False)
x_ft = transform_ft(img_ft).unsqueeze(0).to(device).float()
y_ft = torch.tensor(y_t_lastH, dtype=torch.float32).unsqueeze(0).to(device)

resnet_ft.train()
for epoch in range(3):  # fine-tuning leve
    optimizer.zero_grad()
    pred = resnet_ft(x_ft)
    loss = criterion(pred, y_ft)
    loss.backward()
    optimizer.step()
    print(f"Epoch {epoch+1}: loss={loss.item():.6f}")

# avalia√ß√£o
resnet_ft.eval()
y_pred4 = resnet_ft(x_ft).cpu().detach().numpy().flatten()
mse4, mae4 = evaluate(y_t_lastH, y_pred4)
print(f"Fine-tuning leve ‚Üí MSE={mse4:.4f} | MAE={mae4:.4f}")

plt.plot(y_t_lastH, label="Real")
plt.plot(y_pred4, label="Fine-tuning leve (fc)")
plt.legend(); plt.show()